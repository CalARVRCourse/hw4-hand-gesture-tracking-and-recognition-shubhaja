{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Gesture Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show(window_name, image):\n",
    "    image = cv2.resize(image, (image.shape[1] // 2, image.shape[0] // 2))\n",
    "    cv2.imshow(window_name, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code from thresholding and contours demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actions\n",
    "def hello_world():\n",
    "    pyautogui.write('Hello world!') \n",
    "\n",
    "def zoom_in():  \n",
    "    pyautogui.hotkey('command', '+')  \n",
    "  \n",
    "def zoom_out():  \n",
    "    pyautogui.hotkey('command', '-')  \n",
    "  \n",
    "# def RotateLeft():  \n",
    "#     pyautogui.hotkey('ctrl', 'R', presses=3)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for actions based on gestures\n",
    "\n",
    "\n",
    "\n",
    "def check_action(window_average):\n",
    "\n",
    "    if window_average['finger'] == 2:\n",
    "        hello_world()\n",
    "    elif window_average['finger'] == 3:\n",
    "        zoom_out()\n",
    "    elif window_average['finger'] == 4:\n",
    "        zoom_in()\n",
    "\n",
    "        \n",
    "def check_complex_action(window):\n",
    "    #print(window['angle'])\n",
    "    angle_delta = np.sum(np.convolve(window['angle'], [-1,-1,-1,0,1,1,1], 'valid'))\n",
    "    area_delta = np.sum(np.convolve(window['area'], [-1,-1,-1,0,1,1,1], 'valid'))\n",
    "    if area_delta > 1500:\n",
    "#         print(\"SMALLER\")\n",
    "        pyautogui.hotkey('ctrl', 'down')  \n",
    "        return True\n",
    "    elif area_delta < -1500:\n",
    "#         print(\"BIGGER\")\n",
    "        pyautogui.hotkey('ctrl', 'up') \n",
    "        return True\n",
    "    elif angle_delta > 35:\n",
    "#         print(\"Rot RIGHT\")\n",
    "        pyautogui.hotkey('ctrl', 'right')\n",
    "        return True\n",
    "    elif angle_delta < -35:\n",
    "#         print(\"Rot LEFT\")\n",
    "        pyautogui.hotkey('ctrl', 'left')\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_value = 255\n",
    "max_type = 4\n",
    "max_binary_value = 255\n",
    "trackbar_type = 'Type: \\n 0: Binary \\n 1: Binary Inverted \\n 2: Truncate \\n 3: To Zero \\n 4: To Zero Inverted'\n",
    "trackbar_value = 'Value'\n",
    "trackbar_blur = 'Blur kernel size'\n",
    "window_name = 'Gesture Recognition'\n",
    "isColor = False\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "    \n",
    "cam = cv2.VideoCapture(2)\n",
    "cam.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25) # 0.25 turns OFF auto exp # nitzan\n",
    "cam.set(cv2.CAP_PROP_AUTO_WB, 0.25) # 0.25 turns OFF auto WB # nitzan\n",
    "# cam.set(cv2.CAP_PROP_EXPOSURE, -1.0) # nitzan\n",
    "# cam.set(cv2.CAP_PROP_ISO_SPEED, 6.0) # nitzan\n",
    "\n",
    "#cam.set(cv2.CAP_PROP_BRIGHTNESS, 5.0)\n",
    "cv2.namedWindow(window_name)\n",
    "cv2.createTrackbar(trackbar_type, window_name , 3, max_type, nothing)\n",
    "# Create Trackbar to choose Threshold value\n",
    "cv2.createTrackbar(trackbar_value, window_name , 0, max_value, nothing)\n",
    "# Call the function to initialize\n",
    "cv2.createTrackbar(trackbar_blur, window_name , 1, 20, nothing)\n",
    "# create switch for ON/OFF functionality\n",
    "color_switch = 'Color'\n",
    "cv2.createTrackbar(color_switch, window_name,0,1,nothing)\n",
    "cv2.createTrackbar('Contours', window_name,0,1,nothing)\n",
    "cv2.createTrackbar('Lower Threshold', window_name, 0, 255, nothing)\n",
    "\n",
    "window = {}\n",
    "window_average = {'finger' : 0, 'x' : 0, 'y' : 0, 'MA' : 0, 'ma' : 0, 'angle' : 0}\n",
    "window['finger'] = [0, 0, 0, 0, 0, 0, 0]\n",
    "window['x'] = [0, 0, 0, 0, 0, 0, 0]\n",
    "window['y'] = [0, 0, 0, 0, 0, 0, 0]\n",
    "window['MA'] = [0, 0, 0, 0, 0, 0, 0]\n",
    "window['ma'] = [0, 0, 0, 0, 0, 0, 0]\n",
    "window['angle'] = [0, 0, 0, 0, 0, 0, 0]\n",
    "window['area'] = [0] * 7 # NITZAN\n",
    "\n",
    "prev_seconds = time.time()\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    #0: Binary\n",
    "    #1: Binary Inverted\n",
    "    #2: Threshold Truncated\n",
    "    #3: Threshold to Zero\n",
    "    #4: Threshold to Zero Inverted\n",
    "    threshold_type = cv2.getTrackbarPos(trackbar_type, window_name)\n",
    "    threshold_value = cv2.getTrackbarPos(trackbar_value, window_name)\n",
    "    blur_value = cv2.getTrackbarPos(trackbar_blur, window_name)\n",
    "    blur_value = blur_value+ (  blur_value%2==0)\n",
    "    isColor = (cv2.getTrackbarPos(color_switch, window_name) == 1)\n",
    "    findContours = (cv2.getTrackbarPos('Contours', window_name) == 1)\n",
    "    lower_threshold = cv2.getTrackbarPos('Lower Threshold', window_name)\n",
    "\n",
    "    # PART 0 START\n",
    "    #show('fefe', frame)\n",
    "    # PART 0 END\n",
    "    \n",
    "    # PART 1 START\n",
    "#     lower_HSV = np.array([0, 40, 0], dtype = \"uint8\")  \n",
    "#     upper_HSV = np.array([25, 255, 255], dtype = \"uint8\")  \n",
    "    \n",
    "    lower_HSV = np.array([81, 0, 63], dtype = \"uint8\") # NITZAN \n",
    "    upper_HSV = np.array([204, 124, 140], dtype = \"uint8\")  # NITZAN\n",
    "\n",
    "    convertedHSV = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)  \n",
    "    skinMaskHSV = cv2.inRange(convertedHSV, lower_HSV, upper_HSV)  \n",
    "\n",
    "\n",
    "#     lower_YCrCb = np.array((0, 138, 67), dtype = \"uint8\")  \n",
    "#     upper_YCrCb = np.array((255, 173, 133), dtype = \"uint8\")  \n",
    "    \n",
    "    lower_YCrCb = np.array((40, 138, 67), dtype = \"uint8\")  # NITZAN\n",
    "    upper_YCrCb = np.array((255, 173, 133), dtype = \"uint8\")  # NITZAN\n",
    "\n",
    "    convertedYCrCb = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)  \n",
    "    skinMaskYCrCb = cv2.inRange(convertedYCrCb, lower_YCrCb, upper_YCrCb)  \n",
    "\n",
    "    skinMask = cv2.add(skinMaskHSV,skinMaskYCrCb)  \n",
    "    #show(window_name, skinMask)\n",
    "        \n",
    "    # Erosion and Dilation\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))  \n",
    "    skinMask = cv2.erode(skinMask, kernel, iterations = 2)  \n",
    "    skinMask = cv2.dilate(skinMask, kernel, iterations = 2)  \n",
    "    # blur the mask to help remove noise, then apply the  \n",
    "    # mask to the frame  \n",
    "    skinMask = cv2.GaussianBlur(skinMask, (7, 7), 0) # NITZAN 9,9 --> 7,7\n",
    "    skin = cv2.bitwise_and(frame, frame, mask = skinMask) \n",
    "#     show(window_name, skin)\n",
    "    # PART 1 END\n",
    "    \n",
    "    # PART 2 START\n",
    "    # Binarize the image\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  \n",
    "    gray = cv2.cvtColor(skin, cv2.COLOR_BGR2GRAY)  # NITZAN\n",
    "    \n",
    "#     ret, thresh = cv2.threshold(gray, 0, max_binary_value, cv2.THRESH_BINARY+cv2.THRESH_OTSU )  # SHUBHA: USE WHEN RUNNING PART 2\n",
    "    ret, thresh = cv2.threshold(gray, 0, max_binary_value, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU )  # NITZAN\n",
    "\n",
    "#     show(window_name, thresh)\n",
    "    \n",
    "    # Show connected components\n",
    "    ret, markers, stats, centroids = cv2.connectedComponentsWithStats(thresh,ltype=cv2.CV_16U)  \n",
    "    markers = np.array(markers, dtype=np.uint8)  \n",
    "    label_hue = np.uint8(179*markers/np.max(markers))  \n",
    "    blank_ch = 255*np.ones_like(label_hue)  \n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "    labeled_img[label_hue==0] = 0  \n",
    "#     show(window_name, labeled_img)\n",
    "\n",
    "    statsSortedByArea = stats[np.argsort(stats[:, 4])]  \n",
    "    \n",
    "    if (ret>2):  \n",
    "        try:  \n",
    "            roi = statsSortedByArea[-3][0:4]  \n",
    "            x, y, w, h = roi  \n",
    "            subImg = labeled_img[y:y+h, x:x+w]  \n",
    "            subImg = cv2.cvtColor(subImg, cv2.COLOR_BGR2GRAY);  \n",
    "#             _, contours, _ = cv2.findContours(subImg, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contours, _ = cv2.findContours(subImg, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  # NITZAN\n",
    "            maxCntLength = 0  \n",
    "            for i in range(0,len(contours)):  \n",
    "                cntLength = len(contours[i])  \n",
    "                if(cntLength>maxCntLength):  \n",
    "                    cnt = contours[i]  \n",
    "                    maxCntLength = cntLength  \n",
    "            if(maxCntLength>=5):  \n",
    "                ellipseParam = cv2.fitEllipse(cnt)  \n",
    "                subImg = cv2.cvtColor(subImg, cv2.COLOR_GRAY2RGB);  \n",
    "                subImg = cv2.ellipse(subImg,ellipseParam,(0,255,0),2)  \n",
    "              \n",
    "            subImg = cv2.resize(subImg, (0,0), fx=3, fy=3)          \n",
    "            (x,y),(MA,ma),angle = cv2.fitEllipse(cnt)\n",
    "            \n",
    "            # PART 4: WINDOW AVERAGING START\n",
    "            window['x'].append(x)\n",
    "            window['x'] = window['x'][1:]\n",
    "            window_average['x'] = round(np.average(window['x']))\n",
    "            \n",
    "            window['y'].append(x)\n",
    "            window['y'] = window['y'][1:]\n",
    "            window_average['y'] = round(np.average(window['y']))\n",
    "            \n",
    "            window['MA'].append(MA)\n",
    "            window['MA'] = window['MA'][1:]\n",
    "            window_average['MA'] = round(np.average(window['MA']))\n",
    "            \n",
    "            window['ma'].append(ma)\n",
    "            window['ma'] = window['ma'][1:]\n",
    "            window_average['ma'] = round(np.average(window['ma']))\n",
    "            \n",
    "            window['angle'].append(angle)\n",
    "            window['angle'] = window['angle'][1:]\n",
    "            window_average['angle'] = round(np.average(window['angle']))\n",
    "            \n",
    "            window['area'].append(w*h)\n",
    "            window['area'] = window['area'][1:]\n",
    "            # PART 4: WINDOW AVERAGING END\n",
    " \n",
    "#             cv2.imshow(\"ROI \"+str(2), subImg)\n",
    "#             print(\"Ellipse Center: \" + str((x, y)) + \", Major & Minor Axis: \" + str((MA, ma)) + \", Orientation: \" + str(angle) + '\\n')\n",
    "            \n",
    "            cv2.waitKey(1)  \n",
    "        except:  \n",
    "#             print(\"No hand found\")\n",
    "            pass\n",
    "    # PART 2 END\n",
    "\n",
    "#     # PART 3A START\n",
    "    #ret, thresh = cv2.threshold(gray, 0, max_binary_value, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU )\n",
    "    ret, thresh = cv2.threshold(gray, 0, max_binary_value, cv2.THRESH_BINARY+cv2.THRESH_OTSU )  # NITZAN\n",
    "    thresholdedHandImage = thresh\n",
    "    contours, _ = cv2.findContours(thresholdedHandImage, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)       \n",
    "    contours = sorted(contours,key=cv2.contourArea,reverse=True)\n",
    "    if len(contours)>1:  \n",
    "        largestContour = contours[0]  \n",
    "        hull = cv2.convexHull(largestContour, returnPoints = False)     \n",
    "        for cnt in contours[:1]:  \n",
    "            defects = cv2.convexityDefects(cnt,hull)  \n",
    "            if(not isinstance(defects,type(None))):\n",
    "                thresholdedHandImage = cv2.cvtColor(thresholdedHandImage, cv2.COLOR_GRAY2BGR)\n",
    "                fingerCount = 1\n",
    "                for i in range(defects.shape[0]):  \n",
    "                    s,e,f,d = defects[i,0]  \n",
    "                    start = tuple(cnt[s][0])  \n",
    "                    end = tuple(cnt[e][0])  \n",
    "                    far = tuple(cnt[f][0]) \n",
    "                    \n",
    "                    # UNCOMMENT FOR PART 3A\n",
    "                    # draws countour line around hand and red dots in the contour's defects\n",
    "#                     thresholdedHandImage = cv2.line(thresholdedHandImage,start,end,[0,255,0],2)  \n",
    "#                     thresholdedHandImage = cv2.circle(thresholdedHandImage,far,5,[0,0,255],-1)\n",
    "#                     show(window_name, thresholdedHandImage)\n",
    "                    # UNCOMMENT FOR PART 3A\n",
    "                    \n",
    "                    # PART 3B START\n",
    "                    c_squared = (end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2  \n",
    "                    a_squared = (far[0] - start[0]) ** 2 + (far[1] - start[1]) ** 2  \n",
    "                    b_squared = (end[0] - far[0]) ** 2 + (end[1] - far[1]) ** 2  \n",
    "                    angle = np.arccos((a_squared + b_squared  - c_squared ) / (2 * np.sqrt(a_squared * b_squared )))    \n",
    "\n",
    "                    if angle <= np.pi / 3:  \n",
    "                        fingerCount += 1  \n",
    "                        cv2.circle(thresholdedHandImage, far, 10, [0, 0, 255], -1)\n",
    "#                         thresholdedHandImage = cv2.line(thresholdedHandImage,start,end,[0,255,0],2)  \n",
    "#                         thresholdedHandImage = cv2.circle(thresholdedHandImage,far,5,[0,0,255],-1)\n",
    "#                     show(window_name, thresholdedHandImage)\n",
    "    \n",
    "                # Write window average and finger count into the image start\n",
    "                # PART 4: WINDOW AVERAGING START\n",
    "                window['finger'].append(fingerCount)\n",
    "                window['finger'] = window['finger'][1:]\n",
    "                window_average['finger'] = round(np.average(window['finger']))\n",
    "                # PART 4: WINDOW AVERAGING END\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                height, width, _ = thresholdedHandImage.shape\n",
    "                bottomLeftCornerOfText1 = (int(width * 0.01), int(height * .92)) # NITZAN\n",
    "                bottomLeftCornerOfText2 = (int(width * 0.01), int(height * .98)) # NITZAN\n",
    "                fontScale = 1\n",
    "                fontColor = (255,255,255)\n",
    "                lineType = 2\n",
    "                \n",
    "                cv2.putText(thresholdedHandImage, \"Finger Count: \" + str(fingerCount), bottomLeftCornerOfText1, font, fontScale, fontColor, lineType)\n",
    "                cv2.putText(thresholdedHandImage, \"Window Average: \" + str(window_average['finger']), bottomLeftCornerOfText2, font, fontScale, fontColor, lineType)\n",
    "                #Write window average and finger count into the image end\n",
    "    \n",
    "                show(window_name, thresholdedHandImage)\n",
    "#                 # PART 3B END  \n",
    "#     # PART 3A END\n",
    "    \n",
    "#     # PART 4 START\n",
    "    #check_action(window_average)\n",
    "    \n",
    "    # don't check for action again for 0.5 sec to limit num of commands per second\n",
    "    curr_seconds = time.time() # get curr time\n",
    "    act_ret = False\n",
    "    if (curr_seconds - prev_seconds) > 1.: # if at least 0.5 sec passed then check action\n",
    "        act_ret = check_complex_action(window)\n",
    "        if act_ret: # if action found, reset timer\n",
    "            prev_seconds = time.time()\n",
    "#     # PART 4 END\n",
    "    \n",
    "    k = cv2.waitKey(1) #k is the key pressed\n",
    "    if k == 27 or k==113:  #27, 113 are ascii for escape and q respectively\n",
    "        #exit\n",
    "        cv2.destroyAllWindows()\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
